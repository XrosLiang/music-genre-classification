{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from IPython.display import Audio\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import librosa\n",
    "import ast\n",
    "#import tensorflow_io as tfio\n",
    "import librosa.display\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow import keras\n",
    "\n",
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the small directory\n",
    "SMALL_AUDIO_DIR = 'data/fma_small/'\n",
    "\n",
    "# function to get the paths to all the songs in the small dataset\n",
    "def audio_paths(AUDIO_DIR):\n",
    "    AUDIO_PATHS = []\n",
    "    # iterate through all the directories with songs in them\n",
    "    for path in [os.path.join('data/fma_small/', p) \n",
    "                 for p in os.listdir('data/fma_small/') \n",
    "                 if not (p.endswith('checksums') or p.endswith('.txt') or p.endswith('.DS_Store'))]:\n",
    "        # add all songs to the list\n",
    "        AUDIO_PATHS = AUDIO_PATHS + [os.path.join(path, track).replace('\\\\', '/') for track in os.listdir(path)]\n",
    "    \n",
    "    return AUDIO_PATHS\n",
    "\n",
    "# store all the small paths\n",
    "SMALL_PATHS = audio_paths(SMALL_AUDIO_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoBackendError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\librosa\\core\\audio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0msf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSoundFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msf_desc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m             \u001b[0msr_native\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msf_desc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\soundfile.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[0;32m    628\u001b[0m                                          format, subtype, endian)\n\u001b[1;32m--> 629\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode_int\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclosefd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    630\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missuperset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'r+'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseekable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\soundfile.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[0;32m   1183\u001b[0m         _error_check(_snd.sf_error(file_ptr),\n\u001b[1;32m-> 1184\u001b[1;33m                      \"Error opening {0!r}: \".format(self.name))\n\u001b[0m\u001b[0;32m   1185\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmode_int\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_snd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSFM_WRITE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\soundfile.py\u001b[0m in \u001b[0;36m_error_check\u001b[1;34m(err, prefix)\u001b[0m\n\u001b[0;32m   1356\u001b[0m         \u001b[0merr_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_snd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msf_error_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1357\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefix\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0m_ffi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'replace'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error opening 'data/fma_small/000/000002.mp3': File contains data in an unknown format.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNoBackendError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-5a330c1515cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSMALL_PATHS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmono\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Duration: {:.2f}s, {} samples'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m17\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mAudio\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\librosa\\core\\audio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'PySoundFile failed. Trying audioread instead.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr_native\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__audioread_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m             \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\librosa\\core\\audio.py\u001b[0m in \u001b[0;36m__audioread_load\u001b[1;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 186\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0maudioread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maudio_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0minput_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    187\u001b[0m         \u001b[0msr_native\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m         \u001b[0mn_channels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchannels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\audioread\\__init__.py\u001b[0m in \u001b[0;36maudio_open\u001b[1;34m(path, backends)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;31m# All backends failed!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mNoBackendError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNoBackendError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x, sr = librosa.load(SMALL_PATHS[0], sr=None, mono=True)\n",
    "print('Duration: {:.2f}s, {} samples'.format(x.shape[-1] / sr, x.size))\n",
    "\n",
    "start, end = 7, 17\n",
    "Audio(data=x[start*sr:end*sr], rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load metadata\n",
    "# adapted from https://github.com/mdeff/fma/blob/master/utils.py\n",
    "def metadata_load(filepath):\n",
    "\n",
    "    filename = os.path.basename(filepath)\n",
    "\n",
    "    if 'features' in filename:\n",
    "        return pd.read_csv(filepath, index_col=0, header=[0, 1, 2])\n",
    "\n",
    "    if 'echonest' in filename:\n",
    "        return pd.read_csv(filepath, index_col=0, header=[0, 1, 2])\n",
    "\n",
    "    if 'genres' in filename:\n",
    "        return pd.read_csv(filepath, index_col=0)\n",
    "\n",
    "    if 'tracks' in filename:\n",
    "        tracks = pd.read_csv(filepath, index_col=0, header=[0, 1])\n",
    "\n",
    "        COLUMNS = [('track', 'tags'), ('album', 'tags'), ('artist', 'tags'),\n",
    "                   ('track', 'genres'), ('track', 'genres_all')]\n",
    "        for column in COLUMNS:\n",
    "            tracks[column] = tracks[column].map(ast.literal_eval)\n",
    "\n",
    "        COLUMNS = [('track', 'date_created'), ('track', 'date_recorded'),\n",
    "                   ('album', 'date_created'), ('album', 'date_released'),\n",
    "                   ('artist', 'date_created'), ('artist', 'active_year_begin'),\n",
    "                   ('artist', 'active_year_end')]\n",
    "        for column in COLUMNS:\n",
    "            tracks[column] = pd.to_datetime(tracks[column])\n",
    "\n",
    "        SUBSETS = ('small', 'medium', 'large')\n",
    "        try:\n",
    "            tracks['set', 'subset'] = tracks['set', 'subset'].astype(\n",
    "                    pd.CategoricalDtype(categories=SUBSETS, ordered=True))\n",
    "        except ValueError:\n",
    "            # the categories and ordered arguments were removed in pandas 0.25\n",
    "            tracks['set', 'subset'] = tracks['set', 'subset'].astype(\n",
    "                     pd.CategoricalDtype(categories=SUBSETS, ordered=True))\n",
    "\n",
    "        COLUMNS = [('track', 'genre_top'), ('track', 'license'),\n",
    "                   ('album', 'type'), ('album', 'information'),\n",
    "                   ('artist', 'bio')]\n",
    "        for column in COLUMNS:\n",
    "            tracks[column] = tracks[column].astype('category')\n",
    "\n",
    "        return tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get genre information for each track ID\n",
    "def track_genre_information(GENRE_PATH, TRACKS_PATH, FILE_PATHS, subset):\n",
    "    \"\"\"\n",
    "    GENRE_PATH (str): path to the csv with the genre metadata\n",
    "    TRACKS_PATH (str): path to the csv with the track metadata\n",
    "    FILE_PATHS (list): list of paths to the mp3 files\n",
    "    subset (str): the subset of the data desired\n",
    "    \"\"\"\n",
    "    # get the genre information\n",
    "    genres = pd.read_csv(GENRE_PATH)\n",
    "\n",
    "    # load metadata on all the tracks\n",
    "    tracks = metadata_load(TRACKS_PATH)\n",
    "\n",
    "    # focus on the specific subset tracks\n",
    "    subset_tracks = tracks[tracks['set', 'subset'] <= subset]\n",
    "\n",
    "    # extract track ID and genre information for each track\n",
    "    subset_tracks_genre = np.array([np.array(subset_tracks.index), \n",
    "                                  np.array(subset_tracks['track', 'genre_top'])]).T\n",
    "    \n",
    "    # extract track indices from the file paths\n",
    "    track_indices = []\n",
    "    for path in FILE_PATHS:\n",
    "        track_indices.append(path.split('/')[-1].split('.')[0].lstrip('0'))\n",
    "\n",
    "    # get the genre associated with each file path, thanks to the path ID\n",
    "    track_indices = pd.DataFrame({'file_path':FILE_PATHS,'track_id':np.array(track_indices).astype(int)})\n",
    "    tracks_genre_df = pd.DataFrame({'track_id': subset_tracks_genre[:,0], 'genre': subset_tracks_genre[:,1]})\n",
    "    track_genre_data = track_indices.merge(tracks_genre_df, how='left')\n",
    "    \n",
    "    # label classes with numbers\n",
    "    encoder = LabelEncoder()\n",
    "    track_genre_data['genre_nb'] = encoder.fit_transform(track_genre_data.genre)\n",
    "    \n",
    "    return track_genre_data\n",
    "\n",
    "# get genre information for all tracks from the small subset\n",
    "GENRE_PATH = 'data/fma_metadata/genres.csv'\n",
    "TRACKS_PATH = 'data/fma_metadata/tracks.csv'\n",
    "subset = 'small'\n",
    "\n",
    "small_tracks_genre = track_genre_information(GENRE_PATH, TRACKS_PATH, SMALL_PATHS, subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       file_path track_id    genre  genre_nb\n",
      "0  data/fma_small/000/000002.mp3        2  Hip-Hop         3\n",
      "1  data/fma_small/000/000005.mp3        5  Hip-Hop         3\n",
      "2  data/fma_small/000/000010.mp3       10      Pop         6\n",
      "3  data/fma_small/000/000140.mp3      140     Folk         2\n",
      "4  data/fma_small/000/000141.mp3      141     Folk         2\n"
     ]
    }
   ],
   "source": [
    "# visualize the first few rows to confirm each file path has an associated genre\n",
    "print(small_tracks_genre.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split these paths and associated genres into training and test sets\n",
    "SMALL_AUDIO_TRAIN, SMALL_AUDIO_TEST = train_test_split(SMALL_PATHS, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_label(file_path, genre_df=small_tracks_genre):\n",
    "#     path = file_path.numpy()\n",
    "#     path = path.decode(\"utf-8\")\n",
    "#     label = genre_df.loc[genre_df.file_path == file_path,'genre_nb'].values[0]\n",
    "#     return tf.constant([label])\n",
    "\n",
    "# for i in train_paths_dataset:\n",
    "#     sample = i\n",
    "    \n",
    "# get_label(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the tf datasets for training and testing\n",
    "# store the paths\n",
    "train_paths_dataset = tf.data.Dataset.list_files(SMALL_AUDIO_TRAIN)\n",
    "test_paths_dataset = tf.data.Dataset.list_files(SMALL_AUDIO_TEST)\n",
    "\n",
    "# window size = number of observations we want to use\n",
    "window_size = 100\n",
    "\n",
    "# using librosa to load audio\n",
    "def load_audio(file_path):\n",
    "    path = file_path.numpy()\n",
    "    path = path.decode(\"utf-8\")\n",
    "    \n",
    "    return librosa.load(path, sr=None, mono=True)\n",
    "\n",
    "# define a function to get the label associated with a file path\n",
    "def get_label(file_path, genre_df=small_tracks_genre):\n",
    "    path = file_path.numpy()\n",
    "    path = path.decode(\"utf-8\")\n",
    "    label = genre_df.loc[genre_df.file_path == file_path,'genre_nb'].values[0]\n",
    "    return tf.constant([label])\n",
    "\n",
    "# define a function that extracts the desired features from a file path\n",
    "def get_audio(file_path, window_size=window_size):\n",
    "    audio = tf.py_function(load_audio, [file_path], tf.float32)\n",
    "    audio = tf.expand_dims(audio,-1)\n",
    "    filtered_audio = audio[:window_size,:]\n",
    "\n",
    "    return filtered_audio\n",
    "\n",
    "# process the path\n",
    "def process_path(file_path, window_size=window_size):\n",
    "    label = get_label(file_path)\n",
    "    audio = get_audio(file_path, window_size)\n",
    "\n",
    "    return audio, label\n",
    "\n",
    "# parser, wrap around the processing function and specify output shape\n",
    "def parser(file_path, window_size=window_size):\n",
    "    audio, label = tf.py_function(process_path, [file_path], (tf.float32, tf.int32))\n",
    "    audio.set_shape((window_size,1))\n",
    "    label.set_shape((1,))\n",
    "\n",
    "    return audio, label\n",
    "\n",
    "# create the dataset\n",
    "# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
    "train_data = train_paths_dataset.map(parser) \n",
    "                                    #  num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# batch and prefetch\n",
    "train_data = train_data.batch(32)\n",
    "\n",
    "# `prefetch` lets the dataset fetch batches in the background while the model\n",
    "# is training.\n",
    "train_data = train_data.prefetch(1)\n",
    "\n",
    "\n",
    "# re-create for the test data\n",
    "test_data = test_paths_dataset.map(parser)\n",
    "                                    # num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# batch and prefetch\n",
    "test_data = test_data.batch(32)\n",
    "test_data = test_data.prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a simple model\n",
    "# architecture and structure chosen somewhat randomly, tuning could happen later\n",
    "model = tf.keras.Sequential([\n",
    "                             tf.keras.layers.Conv1D(filters=128,\n",
    "                                                    kernel_size=3,\n",
    "                                                    activation='relu',\n",
    "                                                    input_shape=[window_size,1],\n",
    "                                                    name = 'conv1'),\n",
    "                             \n",
    "                             tf.keras.layers.MaxPooling1D(name='max1'),\n",
    "\n",
    "                             tf.keras.layers.Conv1D(filters=64,\n",
    "                                                    kernel_size=3,\n",
    "                                                    activation='relu',\n",
    "                                                    name='conv2'),\n",
    "                             \n",
    "                             tf.keras.layers.MaxPooling1D(name='max2'),\n",
    "\n",
    "                             tf.keras.layers.Dropout(0.5, name='dropout'),\n",
    "\n",
    "                             tf.keras.layers.Flatten(name='flatten'),\n",
    "                             tf.keras.layers.Dense(512, activation='relu', name='dense1'),\n",
    "                             tf.keras.layers.Dense(8, activation='softmax',name='dense2')                  \n",
    "])\n",
    "\n",
    "# compile\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "60/60 [==============================] - 757s 13s/step - loss: 2.0521 - accuracy: 0.1763\n",
      "Epoch 2/20\n",
      "12/60 [=====>........................] - ETA: 8:46 - loss: 2.0422 - accuracy: 0.1953"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "epochs=20\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate on the test data\n",
    "model.evaluate(test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
